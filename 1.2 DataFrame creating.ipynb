{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4fc70d",
   "metadata": {},
   "source": [
    "**Создание таблицы со статистическими признаками произведений корпуса**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3176b",
   "metadata": {},
   "source": [
    "Импорт Lensky и необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d084e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lensky.lensky import *\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb5ce9",
   "metadata": {},
   "source": [
    "Загрузка корпуса по адресу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85327ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [00:05<00:00, 33.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus('data/corpus_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b01542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Авторов в корпусе: 180\n",
      "Книг в корпусе: 755\n"
     ]
    }
   ],
   "source": [
    "print('Авторов в корпусе:', len(corpus.keys()))\n",
    "print('Книг в корпусе:', len(corpus.subkeys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c4ca4",
   "metadata": {},
   "source": [
    "Создание pd.DataFrame() с элементами корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9add25ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>book</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Авдеев.Варенька.1852.txt</td>\n",
       "      <td>Варенька</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Авдеев.Иванов.1852.txt</td>\n",
       "      <td>Иванов</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Авдеев.Тетрадь_из_записок_Тамарина.1852.txt</td>\n",
       "      <td>Тетрадь_из_записок_Тамарина</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авенариус.Поветрие.1867.txt</td>\n",
       "      <td>Поветрие</td>\n",
       "      <td>Авенариус</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авенариус.Современная_идиллия.1867.txt</td>\n",
       "      <td>Современная_идиллия</td>\n",
       "      <td>Авенариус</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Ясинский.Верочка.1887.txt</td>\n",
       "      <td>Верочка</td>\n",
       "      <td>Ясинский</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Ясинский.Учитель.1888.txt</td>\n",
       "      <td>Учитель</td>\n",
       "      <td>Ясинский</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Яхина.Дети_мои.2018.txt</td>\n",
       "      <td>Дети_мои</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Яхина.Зулейха_открывает_глаза.2015.txt</td>\n",
       "      <td>Зулейха_открывает_глаза</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Яхина.Эшелон_до_Самарканд.2021.txt</td>\n",
       "      <td>Эшелон_до_Самарканд</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        filename                         book  \\\n",
       "0                       Авдеев.Варенька.1852.txt                     Варенька   \n",
       "1                         Авдеев.Иванов.1852.txt                       Иванов   \n",
       "2    Авдеев.Тетрадь_из_записок_Тамарина.1852.txt  Тетрадь_из_записок_Тамарина   \n",
       "3                    Авенариус.Поветрие.1867.txt                     Поветрие   \n",
       "4         Авенариус.Современная_идиллия.1867.txt          Современная_идиллия   \n",
       "..                                           ...                          ...   \n",
       "750                    Ясинский.Верочка.1887.txt                      Верочка   \n",
       "751                    Ясинский.Учитель.1888.txt                      Учитель   \n",
       "752                      Яхина.Дети_мои.2018.txt                     Дети_мои   \n",
       "753       Яхина.Зулейха_открывает_глаза.2015.txt      Зулейха_открывает_глаза   \n",
       "754           Яхина.Эшелон_до_Самарканд.2021.txt          Эшелон_до_Самарканд   \n",
       "\n",
       "        author  year  \n",
       "0       Авдеев  1852  \n",
       "1       Авдеев  1852  \n",
       "2       Авдеев  1852  \n",
       "3    Авенариус  1867  \n",
       "4    Авенариус  1867  \n",
       "..         ...   ...  \n",
       "750   Ясинский  1887  \n",
       "751   Ясинский  1888  \n",
       "752      Яхина  2018  \n",
       "753      Яхина  2015  \n",
       "754      Яхина  2021  \n",
       "\n",
       "[755 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'filename' : [x + '.txt' for x in corpus.subkeys()], \n",
    "                   'book' : list(map(lambda x: x.split('.')[1], corpus.subkeys())),\n",
    "                   'author' : list(map(lambda x: x.split('.')[0], corpus.subkeys())),\n",
    "                   'year' : list(map(lambda x: int(x.split('.')[2]), corpus.subkeys()))})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157553e",
   "metadata": {},
   "source": [
    "Объявим функцию и по имени файла определим век написания книги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4c38417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cent(year):\n",
    "    if year < 1801:\n",
    "        return 18\n",
    "    if year >= 1801 and year < 1901:\n",
    "        return 19\n",
    "    if year >= 1901 and year < 2001:\n",
    "        return 20\n",
    "    if year >= 2001:\n",
    "        return 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "433cf3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>book</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>cent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Авдеев.Варенька.1852.txt</td>\n",
       "      <td>Варенька</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Авдеев.Иванов.1852.txt</td>\n",
       "      <td>Иванов</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Авдеев.Тетрадь_из_записок_Тамарина.1852.txt</td>\n",
       "      <td>Тетрадь_из_записок_Тамарина</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авенариус.Поветрие.1867.txt</td>\n",
       "      <td>Поветрие</td>\n",
       "      <td>Авенариус</td>\n",
       "      <td>1867</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авенариус.Современная_идиллия.1867.txt</td>\n",
       "      <td>Современная_идиллия</td>\n",
       "      <td>Авенариус</td>\n",
       "      <td>1867</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Ясинский.Верочка.1887.txt</td>\n",
       "      <td>Верочка</td>\n",
       "      <td>Ясинский</td>\n",
       "      <td>1887</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Ясинский.Учитель.1888.txt</td>\n",
       "      <td>Учитель</td>\n",
       "      <td>Ясинский</td>\n",
       "      <td>1888</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Яхина.Дети_мои.2018.txt</td>\n",
       "      <td>Дети_мои</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Яхина.Зулейха_открывает_глаза.2015.txt</td>\n",
       "      <td>Зулейха_открывает_глаза</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2015</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Яхина.Эшелон_до_Самарканд.2021.txt</td>\n",
       "      <td>Эшелон_до_Самарканд</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        filename                         book  \\\n",
       "0                       Авдеев.Варенька.1852.txt                     Варенька   \n",
       "1                         Авдеев.Иванов.1852.txt                       Иванов   \n",
       "2    Авдеев.Тетрадь_из_записок_Тамарина.1852.txt  Тетрадь_из_записок_Тамарина   \n",
       "3                    Авенариус.Поветрие.1867.txt                     Поветрие   \n",
       "4         Авенариус.Современная_идиллия.1867.txt          Современная_идиллия   \n",
       "..                                           ...                          ...   \n",
       "750                    Ясинский.Верочка.1887.txt                      Верочка   \n",
       "751                    Ясинский.Учитель.1888.txt                      Учитель   \n",
       "752                      Яхина.Дети_мои.2018.txt                     Дети_мои   \n",
       "753       Яхина.Зулейха_открывает_глаза.2015.txt      Зулейха_открывает_глаза   \n",
       "754           Яхина.Эшелон_до_Самарканд.2021.txt          Эшелон_до_Самарканд   \n",
       "\n",
       "        author  year  cent  \n",
       "0       Авдеев  1852    19  \n",
       "1       Авдеев  1852    19  \n",
       "2       Авдеев  1852    19  \n",
       "3    Авенариус  1867    19  \n",
       "4    Авенариус  1867    19  \n",
       "..         ...   ...   ...  \n",
       "750   Ясинский  1887    19  \n",
       "751   Ясинский  1888    19  \n",
       "752      Яхина  2018    21  \n",
       "753      Яхина  2015    21  \n",
       "754      Яхина  2021    21  \n",
       "\n",
       "[755 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cents = []\n",
    "for year in df['year'].to_numpy():\n",
    "    cents.append(cent(year))\n",
    "df['cent'] = cents\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39298603",
   "metadata": {},
   "source": [
    "Определим длину произведений в словах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29c36c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp(text):\n",
    "    return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61381666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [00:02<00:00, 79.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 180/180 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Wall time: 3.17 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>book</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>cent</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Авдеев.Варенька.1852.txt</td>\n",
       "      <td>Варенька</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "      <td>25469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Авдеев.Иванов.1852.txt</td>\n",
       "      <td>Иванов</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "      <td>27134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Авдеев.Тетрадь_из_записок_Тамарина.1852.txt</td>\n",
       "      <td>Тетрадь_из_записок_Тамарина</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "      <td>25449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авенариус.Поветрие.1867.txt</td>\n",
       "      <td>Поветрие</td>\n",
       "      <td>Авенариус</td>\n",
       "      <td>1867</td>\n",
       "      <td>19</td>\n",
       "      <td>40545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авенариус.Современная_идиллия.1867.txt</td>\n",
       "      <td>Современная_идиллия</td>\n",
       "      <td>Авенариус</td>\n",
       "      <td>1867</td>\n",
       "      <td>19</td>\n",
       "      <td>48633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Ясинский.Верочка.1887.txt</td>\n",
       "      <td>Верочка</td>\n",
       "      <td>Ясинский</td>\n",
       "      <td>1887</td>\n",
       "      <td>19</td>\n",
       "      <td>19274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Ясинский.Учитель.1888.txt</td>\n",
       "      <td>Учитель</td>\n",
       "      <td>Ясинский</td>\n",
       "      <td>1888</td>\n",
       "      <td>19</td>\n",
       "      <td>19355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Яхина.Дети_мои.2018.txt</td>\n",
       "      <td>Дети_мои</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "      <td>121134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Яхина.Зулейха_открывает_глаза.2015.txt</td>\n",
       "      <td>Зулейха_открывает_глаза</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2015</td>\n",
       "      <td>21</td>\n",
       "      <td>109221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Яхина.Эшелон_до_Самарканд.2021.txt</td>\n",
       "      <td>Эшелон_до_Самарканд</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>124743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        filename                         book  \\\n",
       "0                       Авдеев.Варенька.1852.txt                     Варенька   \n",
       "1                         Авдеев.Иванов.1852.txt                       Иванов   \n",
       "2    Авдеев.Тетрадь_из_записок_Тамарина.1852.txt  Тетрадь_из_записок_Тамарина   \n",
       "3                    Авенариус.Поветрие.1867.txt                     Поветрие   \n",
       "4         Авенариус.Современная_идиллия.1867.txt          Современная_идиллия   \n",
       "..                                           ...                          ...   \n",
       "750                    Ясинский.Верочка.1887.txt                      Верочка   \n",
       "751                    Ясинский.Учитель.1888.txt                      Учитель   \n",
       "752                      Яхина.Дети_мои.2018.txt                     Дети_мои   \n",
       "753       Яхина.Зулейха_открывает_глаза.2015.txt      Зулейха_открывает_глаза   \n",
       "754           Яхина.Эшелон_до_Самарканд.2021.txt          Эшелон_до_Самарканд   \n",
       "\n",
       "        author  year  cent     len  \n",
       "0       Авдеев  1852    19   25469  \n",
       "1       Авдеев  1852    19   27134  \n",
       "2       Авдеев  1852    19   25449  \n",
       "3    Авенариус  1867    19   40545  \n",
       "4    Авенариус  1867    19   48633  \n",
       "..         ...   ...   ...     ...  \n",
       "750   Ясинский  1887    19   19274  \n",
       "751   Ясинский  1888    19   19355  \n",
       "752      Яхина  2018    21  121134  \n",
       "753      Яхина  2015    21  109221  \n",
       "754      Яхина  2021    21  124743  \n",
       "\n",
       "[755 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df['len'] = corpus.apply(sp).apply(len).subvalues()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a917b50a",
   "metadata": {},
   "source": [
    "Загрузим предобработанный токенезированный корпус "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04c01c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [00:04<00:00, 43.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_cleared = Corpus('data/corpus_ru_tokenized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b22ae4",
   "metadata": {},
   "source": [
    "Определим количество уникальных слов в произведениях (богатство их словаря)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77ae38c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [00:18<00:00,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Wall time: 18.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>book</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>cent</th>\n",
       "      <th>len</th>\n",
       "      <th>len_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Авдеев.Варенька.1852.txt</td>\n",
       "      <td>Варенька</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "      <td>25469</td>\n",
       "      <td>6555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Авдеев.Иванов.1852.txt</td>\n",
       "      <td>Иванов</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "      <td>27134</td>\n",
       "      <td>7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Авдеев.Тетрадь_из_записок_Тамарина.1852.txt</td>\n",
       "      <td>Тетрадь_из_записок_Тамарина</td>\n",
       "      <td>Авдеев</td>\n",
       "      <td>1852</td>\n",
       "      <td>19</td>\n",
       "      <td>25449</td>\n",
       "      <td>6731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авенариус.Поветрие.1867.txt</td>\n",
       "      <td>Поветрие</td>\n",
       "      <td>Авенариус</td>\n",
       "      <td>1867</td>\n",
       "      <td>19</td>\n",
       "      <td>40545</td>\n",
       "      <td>12694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авенариус.Современная_идиллия.1867.txt</td>\n",
       "      <td>Современная_идиллия</td>\n",
       "      <td>Авенариус</td>\n",
       "      <td>1867</td>\n",
       "      <td>19</td>\n",
       "      <td>48633</td>\n",
       "      <td>13909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Ясинский.Верочка.1887.txt</td>\n",
       "      <td>Верочка</td>\n",
       "      <td>Ясинский</td>\n",
       "      <td>1887</td>\n",
       "      <td>19</td>\n",
       "      <td>19274</td>\n",
       "      <td>6392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Ясинский.Учитель.1888.txt</td>\n",
       "      <td>Учитель</td>\n",
       "      <td>Ясинский</td>\n",
       "      <td>1888</td>\n",
       "      <td>19</td>\n",
       "      <td>19355</td>\n",
       "      <td>6295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Яхина.Дети_мои.2018.txt</td>\n",
       "      <td>Дети_мои</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "      <td>121134</td>\n",
       "      <td>31275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Яхина.Зулейха_открывает_глаза.2015.txt</td>\n",
       "      <td>Зулейха_открывает_глаза</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2015</td>\n",
       "      <td>21</td>\n",
       "      <td>109221</td>\n",
       "      <td>27269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Яхина.Эшелон_до_Самарканд.2021.txt</td>\n",
       "      <td>Эшелон_до_Самарканд</td>\n",
       "      <td>Яхина</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>124743</td>\n",
       "      <td>29617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        filename                         book  \\\n",
       "0                       Авдеев.Варенька.1852.txt                     Варенька   \n",
       "1                         Авдеев.Иванов.1852.txt                       Иванов   \n",
       "2    Авдеев.Тетрадь_из_записок_Тамарина.1852.txt  Тетрадь_из_записок_Тамарина   \n",
       "3                    Авенариус.Поветрие.1867.txt                     Поветрие   \n",
       "4         Авенариус.Современная_идиллия.1867.txt          Современная_идиллия   \n",
       "..                                           ...                          ...   \n",
       "750                    Ясинский.Верочка.1887.txt                      Верочка   \n",
       "751                    Ясинский.Учитель.1888.txt                      Учитель   \n",
       "752                      Яхина.Дети_мои.2018.txt                     Дети_мои   \n",
       "753       Яхина.Зулейха_открывает_глаза.2015.txt      Зулейха_открывает_глаза   \n",
       "754           Яхина.Эшелон_до_Самарканд.2021.txt          Эшелон_до_Самарканд   \n",
       "\n",
       "        author  year  cent     len  len_unique  \n",
       "0       Авдеев  1852    19   25469        6555  \n",
       "1       Авдеев  1852    19   27134        7549  \n",
       "2       Авдеев  1852    19   25449        6731  \n",
       "3    Авенариус  1867    19   40545       12694  \n",
       "4    Авенариус  1867    19   48633       13909  \n",
       "..         ...   ...   ...     ...         ...  \n",
       "750   Ясинский  1887    19   19274        6392  \n",
       "751   Ясинский  1888    19   19355        6295  \n",
       "752      Яхина  2018    21  121134       31275  \n",
       "753      Яхина  2015    21  109221       27269  \n",
       "754      Яхина  2021    21  124743       29617  \n",
       "\n",
       "[755 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df['len_unique'] = corpus_cleared.apply(lambda x: len(np.unique(x.split()))).subvalues()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a31c0",
   "metadata": {},
   "source": [
    "Воспользуемся новым словарем частотных слов О. Н. Ляшевская, С. А. Шаров, Частотный словарь современного русского языка (на материалах Национального корпуса русского языка). М.: Азбуковник, 2009. для определения количества слов, не попадающих в 20 000 самых популярных в языке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd2412f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\DDPronin\\\\PyCharm\\\\RU Classic Literature graphs\\\\data\\\\LEMMY_FREQ.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19468\\1046291327.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:\\DDPronin\\PyCharm\\RU Classic Literature graphs\\data\\LEMMY_FREQ.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdic_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'WORD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\DDPronin\\\\PyCharm\\\\RU Classic Literature graphs\\\\data\\\\LEMMY_FREQ.csv'"
     ]
    }
   ],
   "source": [
    "dic = pd.read_csv('D:\\DDPronin\\PyCharm\\RU Classic Literature graphs\\data\\LEMMY_FREQ.csv')\n",
    "dic_words = set(dic['WORD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdf9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniq_words_not_in_pop(book):\n",
    "    book = np.array(book.split())\n",
    "    uniq = np.unique(book)\n",
    "    n = 0\n",
    "    for word in uniq:\n",
    "        if word not in dic_words and len(book[book==word]) > 3:\n",
    "            n += 1\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['uniq_words_not_in_pop'] = corpus_cleared.apply(uniq_words_not_in_pop).subvalues()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593bd65",
   "metadata": {},
   "source": [
    "С помощью того же словаря оценим среднюю частоту ipm слова в произведении (какова средняя частота употребляемых в книге слов?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63af70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_freq(book):\n",
    "    book = np.array(book.split())\n",
    "    top = list(pd.Series(book).value_counts().index)[:1000]\n",
    "    freqs = 0\n",
    "    n = 0\n",
    "    for word in top:\n",
    "        if word in dic_words:\n",
    "            freqs += dic[dic['WORD']==word]['FREQ'].to_numpy()[0]\n",
    "            n += 1\n",
    "    return freqs/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['mean_freq1k'] = corpus_cleared.apply(mean_freq).subvalues()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ee115",
   "metadata": {},
   "source": [
    "Воспользуемся библиотекой Dostoyevsky для классификации предложений текстов. Вычислим среднее по тексту для каждого из возможных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize\n",
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "model = FastTextSocialNetworkModel(tokenizer=tokenizer)\n",
    "\n",
    "def tonalnost(book):\n",
    "    substrings = list(sentenize(book))\n",
    "    sents = []\n",
    "    for i in range(len(substrings)):\n",
    "        sents.append(substrings[i].text)\n",
    "    messages = sents\n",
    "    results = model.predict(messages, k=2)\n",
    "    neu, pos, neg, sp, sk = 0, 0, 0, 0, 0\n",
    "    n = 0\n",
    "    for message, sentiment in zip(messages, results):\n",
    "        if 'neutral' not in sentiment.keys():\n",
    "            sentiment['neutral'] = 0\n",
    "        if 'positive' not in sentiment.keys():\n",
    "            sentiment['positive'] = 0\n",
    "        if 'negative' not in sentiment.keys():\n",
    "            sentiment['negative'] = 0\n",
    "        if 'speech' not in sentiment.keys():\n",
    "            sentiment['speech'] = 0\n",
    "        if 'skip' not in sentiment.keys():\n",
    "            sentiment['skip'] = 0\n",
    "        neu += sentiment['neutral']\n",
    "        pos += sentiment['positive']\n",
    "        neg += sentiment['negative']\n",
    "        sp += sentiment['speech']\n",
    "        sk += sentiment['skip']\n",
    "        n += 1\n",
    "    return {'neutral' : neu/n, 'positive' : pos/n, 'negative' : neg/n, 'speech' : sp/n, 'skip' : sk/n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70991381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = corpus.apply(tonalnost).subvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ee0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "neu = []\n",
    "pos = []\n",
    "neg = []\n",
    "sp = []\n",
    "sk = []\n",
    "for r in res:\n",
    "    neu.append(r['neutral'])\n",
    "    pos.append(r['positive'])\n",
    "    neg.append(r['negative'])\n",
    "    sp.append(r['speech'])\n",
    "    sk.append(r['skip'])\n",
    "df['dost_neu'] = neu\n",
    "df['dost_pos'] = pos\n",
    "df['dost_neg'] = neg\n",
    "df['dost_sp'] = sp\n",
    "df['dost_sk'] = sk\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6d6c3",
   "metadata": {},
   "source": [
    "Найдем долю слов, которая не попадает в список 20 000 самых частотных слов в языке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e2b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['part_unique'] = df['len_unique']/df['len']\n",
    "df['part_uniq_words_not_in_pop'] = df['uniq_words_not_in_pop']/df['len_unique']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76237686",
   "metadata": {},
   "source": [
    "Рассчитаем среднюю длину слова в произведении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize, sentenize\n",
    "\n",
    "def mean_word_len(book):\n",
    "    subs = list(tokenize(book))\n",
    "    words = []\n",
    "    for sub in subs:\n",
    "        words.append(len(sub.text))\n",
    "    return np.mean(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a6c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['mean_word_len'] = corpus.apply(mean_word_len).subvalues()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06391fb6",
   "metadata": {},
   "source": [
    "Рассчитаем среднюю длину предложения в произведении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_sent_len(book):\n",
    "    subs = list(sentenize(book))\n",
    "    sents = []\n",
    "    for sub in subs:\n",
    "        sents.append(len(list(tokenize(sub.text)))-1) \n",
    "    return np.mean(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['mean_sent_len'] = corpus.apply(mean_sent_len).subvalues()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400b850",
   "metadata": {},
   "source": [
    "Определим долю каждой из частей речи в произведениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66572627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "from slovnet import Morph\n",
    "from razdel import tokenize\n",
    "navec = Navec.load('models//navec_news_v1_1B_250K_300d_100q.tar')\n",
    "morph = Morph.load('models//slovnet_morph_news_v1.tar')\n",
    "morph.navec(navec)\n",
    "\n",
    "def morphing(book):\n",
    "    tokens = morph([x.text for x in list(tokenize(book))]).tokens\n",
    "    res = []\n",
    "    for token in tokens:\n",
    "        res.append(token.pos)\n",
    "    len_ = len(book.split())\n",
    "    return {'ADJ' : res.count('ADJ')/len_, \n",
    "           'ADP' : res.count('ADP')/len_,\n",
    "           'ADV' : res.count('ADV')/len_,\n",
    "           'AUX' : res.count('AUX')/len_,\n",
    "           'CCONJ' : res.count('CCONJ')/len_,\n",
    "           'DET' : res.count('DET')/len_,\n",
    "           'INTJ' : res.count('INTJ')/len_,\n",
    "           'NOUN' : res.count('NOUN')/len_,\n",
    "           'NUM' : res.count('NUM')/len_,\n",
    "           'PART' : res.count('PART')/len_,\n",
    "           'PRON' : res.count('PRON')/len_,\n",
    "           'PROPN' : res.count('PROPN')/len_,\n",
    "           'PUNCT' : res.count('PUNCT')/len_,\n",
    "           'SCONJ' : res.count('SCONJ')/len_,\n",
    "           'PUNCT' : res.count('PUNCT')/len_,\n",
    "           'SYM' : res.count('SYM')/len_,\n",
    "           'VERB' : res.count('VERB')/len_,\n",
    "           'X' : res.count('X')/len_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = corpus.apply(morphing).subvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'ADJ' : [],\n",
    "'ADP' : [],\n",
    "'ADV' : [],\n",
    "'AUX' : [],\n",
    "'CCONJ' : [],\n",
    "'DET' : [],\n",
    "'INTJ' :[],\n",
    "'NOUN' : [],\n",
    "'NUM' : [],\n",
    "'PART' : [],\n",
    "'PRON' : [],\n",
    "'PROPN' : [],\n",
    "'PUNCT' : [],\n",
    "'SCONJ' : [],\n",
    "'SYM' : [],\n",
    "'VERB' : [],\n",
    "'X' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd697c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in res:\n",
    "    for key in m.keys():\n",
    "        m[key].append(r[key])\n",
    "for key in m.keys():\n",
    "        df[key] = m[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb10a89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da04d8",
   "metadata": {},
   "source": [
    "Сохраним результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('data/RuLitStat.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
